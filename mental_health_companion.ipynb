{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgHW-YFEZUWT"
      },
      "outputs": [],
      "source": [
        "#verifying gpu\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing required libraries\n",
        "!pip install -q transformers datasets accelerate bitsandbytes peft sentencepiece"
      ],
      "metadata": {
        "id": "_8b3bO5qZluG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"go_emotions\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "riYIgTdkalo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#coverting 27 emotions to 5\n",
        "label_names = dataset[\"train\"].features[\"labels\"].feature.names\n",
        "print(label_names)\n",
        "\n",
        "emotion_groups = {\n",
        "    \"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
        "    \"sadness\": [\"sadness\", \"disappointment\", \"grief\", \"remorse\", \"embarrassment\"],\n",
        "    \"anxiety\": [\"fear\", \"nervousness\", \"confusion\"],\n",
        "    \"positive\": [\"joy\", \"love\", \"gratitude\", \"admiration\", \"approval\", \"excitement\", \"optimism\", \"relief\", \"pride\", \"caring\", \"desire\"],\n",
        "    \"neutral\": [\"neutral\"]\n",
        "}\n",
        "\n",
        "label_to_group = {}\n",
        "\n",
        "for idx, name in enumerate(label_names):\n",
        "    for group, emotions in emotion_groups.items():\n",
        "        if name in emotions:\n",
        "            label_to_group[idx] = group\n",
        "\n",
        "def convert_labels(example):\n",
        "    if len(example[\"labels\"]) > 0:\n",
        "        original_label = example[\"labels\"][0]\n",
        "        example[\"label_text\"] = label_to_group.get(original_label, \"neutral\")\n",
        "    else:\n",
        "        example[\"label_text\"] = \"neutral\"\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(convert_labels)\n",
        "\n",
        "final_labels = [\"anger\", \"sadness\", \"anxiety\", \"positive\", \"neutral\"]\n",
        "\n",
        "label_encoding = {label: i for i, label in enumerate(final_labels)}\n",
        "print(label_encoding)\n",
        "\n",
        "def encode_labels(example):\n",
        "    example[\"labels\"] = label_encoding[example[\"label_text\"]]\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(encode_labels)\n",
        "\n",
        "dataset = dataset.remove_columns([\"label_text\"])\n",
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "id": "pSauRS79kXYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text preprocessing\n",
        "import re\n",
        "\n",
        "#cleaning text\n",
        "def clean_text(example):\n",
        "    text = example[\"text\"]\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    example[\"text\"] = text\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(clean_text)\n",
        "\n",
        "#removing very short samples\n",
        "def remove_short(example):\n",
        "    return len(example[\"text\"].split()) > 2\n",
        "\n",
        "dataset = dataset.filter(remove_short)\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "train_labels = dataset[\"train\"][\"labels\"]\n",
        "Counter(train_labels)\n",
        "\n",
        "#tokenization\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(\n",
        "    [\"text\"]\n",
        ")\n",
        "\n",
        "tokenized_dataset.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "\n",
        "tokenized_dataset[\"train\"][0]\n",
        "\n",
        "from datasets import DatasetDict\n",
        "\n",
        "train_test = tokenized_dataset[\"train\"].train_test_split(test_size=0.1)\n",
        "\n",
        "dataset = DatasetDict({\n",
        "    \"train\": train_test[\"train\"],\n",
        "    \"validation\": train_test[\"test\"],\n",
        "    \"test\": tokenized_dataset[\"test\"]\n",
        "})\n",
        "\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n"
      ],
      "metadata": {
        "id": "nduB36g6mRGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RoBERTa classification model\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "#Load Model\n",
        "num_labels = 5\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "#Define Evaluation Metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average=\"weighted\"\n",
        "    )\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "    }\n",
        "\n",
        "#Training Configuration\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "#Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "#Train\n",
        "trainer.train()\n",
        "\n",
        "#Evaluate on Test Set\n",
        "results = trainer.evaluate(dataset[\"test\"])\n",
        "print(\"\\nTest Results:\")\n",
        "print(results)\n",
        "\n",
        "#Confusion Matrix\n",
        "predictions = trainer.predict(dataset[\"test\"])\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "labels = predictions.label_ids\n",
        "\n",
        "cm = confusion_matrix(labels, preds)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oJVDSzwZkht4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE MODEL Logistic Regression for comparision\n",
        "\n",
        "from datasets import load_dataset\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reload dataset fresh\n",
        "raw_dataset = load_dataset(\"go_emotions\")\n",
        "\n",
        "\n",
        "label_names = raw_dataset[\"train\"].features[\"labels\"].feature.names\n",
        "\n",
        "emotion_groups = {\n",
        "    \"anger\": [\"anger\", \"annoyance\", \"disapproval\"],\n",
        "    \"sadness\": [\"sadness\", \"disappointment\", \"grief\", \"remorse\", \"embarrassment\"],\n",
        "    \"anxiety\": [\"fear\", \"nervousness\", \"confusion\"],\n",
        "    \"positive\": [\"joy\", \"love\", \"gratitude\", \"admiration\", \"approval\", \"excitement\", \"optimism\", \"relief\", \"pride\", \"caring\", \"desire\"],\n",
        "    \"neutral\": [\"neutral\"]\n",
        "}\n",
        "\n",
        "label_to_group = {}\n",
        "for idx, name in enumerate(label_names):\n",
        "    for group, emotions in emotion_groups.items():\n",
        "        if name in emotions:\n",
        "            label_to_group[idx] = group\n",
        "\n",
        "final_labels = [\"anger\", \"sadness\", \"anxiety\", \"positive\", \"neutral\"]\n",
        "label_encoding = {label: i for i, label in enumerate(final_labels)}\n",
        "\n",
        "def convert_labels(example):\n",
        "    if len(example[\"labels\"]) > 0:\n",
        "        original_label = example[\"labels\"][0]\n",
        "        group = label_to_group.get(original_label, \"neutral\")\n",
        "    else:\n",
        "        group = \"neutral\"\n",
        "    example[\"labels\"] = label_encoding[group]\n",
        "    return example\n",
        "\n",
        "raw_dataset = raw_dataset.map(convert_labels)\n",
        "\n",
        "# ----- Clean text -----\n",
        "def clean_text(example):\n",
        "    text = example[\"text\"].lower()\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    example[\"text\"] = text\n",
        "    return example\n",
        "\n",
        "raw_dataset = raw_dataset.map(clean_text)\n",
        "\n",
        "# Remove very short samples\n",
        "raw_dataset = raw_dataset.filter(lambda x: len(x[\"text\"].split()) > 2)\n",
        "\n",
        "# ----- Prepare data -----\n",
        "train_texts = raw_dataset[\"train\"][\"text\"]\n",
        "train_labels = raw_dataset[\"train\"][\"labels\"]\n",
        "\n",
        "test_texts = raw_dataset[\"test\"][\"text\"]\n",
        "test_labels = raw_dataset[\"test\"][\"labels\"]\n",
        "\n",
        "# ----- TF-IDF -----\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "# ----- Logistic Regression -----\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, train_labels)\n",
        "\n",
        "preds = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(test_labels, preds)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, preds, average=\"weighted\")\n",
        "\n",
        "print(\"Baseline Model Results:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "\n",
        "cm = confusion_matrix(test_labels, preds)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Baseline Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_sZd1_xtfan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crisis Detection Module\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# High-Risk Keyword List\n",
        "high_risk_keywords = [\n",
        "    \"kill myself\",\n",
        "    \"want to die\",\n",
        "    \"end my life\",\n",
        "    \"suicide\",\n",
        "    \"harm myself\",\n",
        "    \"no reason to live\",\n",
        "    \"i can't go on\",\n",
        "    \"i dont want to live\",\n",
        "    \"i hate my life\"\n",
        "]\n",
        "\n",
        "# Emotion Labels (must match your label encoding)\n",
        "label_map = {0: \"anger\", 1: \"sadness\", 2: \"anxiety\", 3: \"positive\", 4: \"neutral\"}\n",
        "\n",
        "# Threshold for severe distress\n",
        "DISTRESS_THRESHOLD = 0.75\n",
        "\n",
        "# Crisis Detection Function\n",
        "\n",
        "def crisis_detection(text):\n",
        "\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    # Explicit High-Risk Keyword Check\n",
        "    for phrase in high_risk_keywords:\n",
        "        if phrase in text_lower:\n",
        "            return {\n",
        "                \"risk_level\": \"HIGH\",\n",
        "                \"reason\": \"Explicit suicidal intent detected\"\n",
        "            }\n",
        "\n",
        "    # Emotion-Based Detection\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = F.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    confidence, predicted_class = torch.max(probs, dim=1)\n",
        "\n",
        "    predicted_label = label_map[predicted_class.item()]\n",
        "    confidence = confidence.item()\n",
        "\n",
        "    return {\n",
        "        \"risk_level\": \"SAFE\",\n",
        "        \"reason\": \"No crisis indicators detected\"\n",
        "    }\n",
        "\n",
        "# Emergency Response Function\n",
        "\n",
        "def emergency_response(risk_info):\n",
        "\n",
        "    if risk_info[\"risk_level\"] == \"HIGH\":\n",
        "        return (\n",
        "            \"I'm really sorry that you're feeling this way. \"\n",
        "            \"It sounds like you're going through something very painful. \"\n",
        "            \"You don‚Äôt have to handle this alone.\\n\\n\"\n",
        "            \"Please consider reaching out to a trusted person or a mental health professional immediately.\\n\"\n",
        "            \"If you're in immediate danger, please contact local emergency services.\"\n",
        "        )\n",
        "\n",
        "    elif risk_info[\"risk_level\"] == \"SEVERE\":\n",
        "        return (\n",
        "            \"I can sense that you're going through a very difficult time. \"\n",
        "            \"Your feelings are valid and important.\\n\\n\"\n",
        "            \"It might help to talk to someone you trust or consider seeking professional support. \"\n",
        "            \"Would you like to try a short grounding exercise together?\"\n",
        "        )\n",
        "\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "EpkReQbPuP0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes accelerate"
      ],
      "metadata": {
        "id": "lBHxzAyvwYnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tiny Llama for empathetic response generation\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "# 4-bit quantization config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "# Load tokenizer\n",
        "tiny_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Load model safely\n",
        "tiny_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "tiny_model.eval()"
      ],
      "metadata": {
        "id": "_CR676WSxWDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendation System\n",
        "\n",
        "# Emotion-aware structured recommendations\n",
        "recommendation_map = {\n",
        "    \"anxiety\": {\n",
        "        \"title\": \"Managing Anxiety\",\n",
        "        \"suggestions\": [\n",
        "            \"Try the 4-7-8 breathing technique for 2 minutes.\",\n",
        "            \"Break your study tasks into smaller, manageable goals.\",\n",
        "            \"Take a short 5-minute walk to reset your focus.\",\n",
        "            \"Limit caffeine and hydrate well.\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"sadness\": {\n",
        "        \"title\": \"Coping with Sadness\",\n",
        "        \"suggestions\": [\n",
        "            \"Write down what you're feeling in a journal.\",\n",
        "            \"Reach out to someone you trust and talk openly.\",\n",
        "            \"Engage in a small activity you usually enjoy.\",\n",
        "            \"Practice self-compassion ‚Äî remind yourself that it's okay to feel this way.\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"anger\": {\n",
        "        \"title\": \"Handling Anger\",\n",
        "        \"suggestions\": [\n",
        "            \"Pause and take 5 slow deep breaths.\",\n",
        "            \"Step away from the triggering situation temporarily.\",\n",
        "            \"Channel energy into physical movement (stretching or walking).\",\n",
        "            \"Reflect before responding to avoid impulsive reactions.\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"positive\": {\n",
        "        \"title\": \"Maintaining Positivity\",\n",
        "        \"suggestions\": [\n",
        "            \"Keep doing what‚Äôs working for you.\",\n",
        "            \"Express gratitude for something today.\",\n",
        "            \"Support someone else who may need encouragement.\"\n",
        "        ]\n",
        "    },\n",
        "\n",
        "    \"neutral\": {\n",
        "        \"title\": \"General Well-being\",\n",
        "        \"suggestions\": [\n",
        "            \"Maintain a balanced routine with sleep and hydration.\",\n",
        "            \"Check in with your emotions throughout the day.\",\n",
        "            \"Take small mindful breaks during tasks.\"\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Recommendation generator function\n",
        "def generate_recommendation(emotion):\n",
        "\n",
        "    if emotion not in recommendation_map:\n",
        "        return \"\"\n",
        "\n",
        "    rec = recommendation_map[emotion]\n",
        "\n",
        "    response = f\"\\n\\n--- {rec['title']} ---\\n\"\n",
        "\n",
        "    for i, suggestion in enumerate(rec[\"suggestions\"], 1):\n",
        "        response += f\"{i}. {suggestion}\\n\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "jf3Z-5Q4z1VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final integration\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def chatbot(user_input):\n",
        "\n",
        "    # Crisis Detection\n",
        "\n",
        "    risk_info = crisis_detection(user_input)\n",
        "\n",
        "    if risk_info[\"risk_level\"] == \"HIGH\":\n",
        "        return emergency_response(risk_info)\n",
        "\n",
        "    if risk_info[\"risk_level\"] == \"SEVERE\":\n",
        "        return emergency_response(risk_info)\n",
        "\n",
        "    # Emotion Prediction\n",
        "    inputs = tokenizer(user_input, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = F.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "    confidence, predicted_class = torch.max(probs, dim=1)\n",
        "    predicted_label = label_map[predicted_class.item()]\n",
        "\n",
        "    # TinyLlama Response\n",
        "    prompt = f\"\"\"\n",
        "You are a compassionate mental health assistant.\n",
        "The user is feeling {predicted_label}.\n",
        "Respond with empathy, validation, and gentle support.\n",
        "Keep the response under 6 sentences.\n",
        "\n",
        "User: {user_input}\n",
        "Assistant:\n",
        "\"\"\"\n",
        "\n",
        "    tiny_inputs = tiny_tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tiny_outputs = tiny_model.generate(\n",
        "            **tiny_inputs,\n",
        "            max_new_tokens=200,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            do_sample=True\n",
        "        )\n",
        "\n",
        "    response_text = tiny_tokenizer.decode(tiny_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Clean assistant prefix if repeated\n",
        "    if \"Assistant:\" in response_text:\n",
        "        response_text = response_text.split(\"Assistant:\")[-1].strip()\n",
        "\n",
        "    # Structured Recommendation\n",
        "\n",
        "    recommendation_text = generate_recommendation(predicted_label)\n",
        "\n",
        "    # Final Output\n",
        "    final_response = response_text + recommendation_text\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "mm9c3OaP0cDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "JfPtnzDA11_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Wrapper function for Gradio chat\n",
        "def chat_interface(user_message, chat_history):\n",
        "    bot_response = chatbot(user_message)\n",
        "    chat_history.append((user_message, bot_response))\n",
        "    return \"\", chat_history\n",
        "\n",
        "# UI Layout\n",
        "with gr.Blocks(theme=gr.themes.Soft()) as app:\n",
        "\n",
        "    # -------- HOME PAGE --------\n",
        "    home_page = gr.Column(visible=True)\n",
        "    with home_page:\n",
        "        gr.Markdown(\"# AI Mental Health Companion\")\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            Welcome to the AI-powered emotional support assistant for students.\n",
        "\n",
        "            This system:\n",
        "            - Detects emotional state\n",
        "            - Provides empathetic responses\n",
        "            - Suggests coping strategies\n",
        "            - Includes crisis safety detection\n",
        "\n",
        "            ‚ö†Ô∏è This chatbot is not a replacement for professional mental health support.\n",
        "            \"\"\"\n",
        "        )\n",
        "        start_button = gr.Button(\"Start Chat üí¨\")\n",
        "\n",
        "    # -------- CHAT PAGE --------\n",
        "    chat_page = gr.Column(visible=False)\n",
        "    with chat_page:\n",
        "        gr.Markdown(\"## üí¨ Talk to the Assistant\")\n",
        "\n",
        "        chatbot_ui = gr.Chatbot()\n",
        "        msg = gr.Textbox(placeholder=\"Type your message here...\")\n",
        "        clear = gr.Button(\"Clear Chat\")\n",
        "        back_button = gr.Button(\"‚¨Ö Back to Home\")\n",
        "\n",
        "        msg.submit(chat_interface, [msg, chatbot_ui], [msg, chatbot_ui])\n",
        "        clear.click(lambda: [], None, chatbot_ui)\n",
        "\n",
        "    # -------- Navigation Logic --------\n",
        "    def go_to_chat():\n",
        "        return gr.update(visible=False), gr.update(visible=True)\n",
        "\n",
        "    def go_to_home():\n",
        "        return gr.update(visible=True), gr.update(visible=False)\n",
        "\n",
        "    start_button.click(go_to_chat, outputs=[home_page, chat_page])\n",
        "    back_button.click(go_to_home, outputs=[home_page, chat_page])\n",
        "\n",
        "app.launch()"
      ],
      "metadata": {
        "id": "vynO68DK13H4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}